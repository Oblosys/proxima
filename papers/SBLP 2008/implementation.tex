\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[latin1]{inputenc}  

\usepackage{../Utils}
\usepackage{implementation}     
\sloppy

\title{Beyond ASCII -- parsing programs with graphical presentations \\{\small \version}}

\author{Martijn M. Schrage\inst{1}}


\address{Institute of Information and Computing Sciences\\ Utrecht University\\
    Utrecht, The Netherlands
  \email{martijn@cs.uu.nl}
}

\begin{document} 

\maketitle

\begin{abstract}

% 15 lines
Proxima is generic structure editor suitable for a wide range of documents. Proxima combines editing on the document structure as well with edit operations on its presentation (free-text editing). Applications of Proxima include word-processor and spread-sheet editors, but system is also very suitable for implementing source editors for programming languages.

Edit operations on the presentation require that a modified presentation can be parsed to yield an updated document. This is complicated by the fact that presentations in Proxima are not restricted to text, but may contain graphical elements. For example, a power operator may be presented as $3^2$. Such graphical presentations may not be edited at the presentation level, but they may contain textual children that may be edited (e.g.\ the 3 and the 2 in $3^2$). 

This paper shows the scanning and parsing process that is employed by Proxima to parse presentations that are combination of text and graphical elements. The scanner takes a regular-expression specification of the tokens. The parsers for textual parts of the presentation are specified using Haskell combinator parsers. Whitespace in the presentation can be handled automatically if desired.

\end{abstract}
     
\section{Introduction}

Proxima is a generic structure editor suitable for a range of different kinds of documents. A key feature of Proxima is that it combines structural editing with editing on the presentation of the document. For a source code editor, a structural edit operation is based on the abstract syntax. For example means that a program source can be edited based on its abstract syntax(e.g.\ element in a list, causing freely edited textually if 

A Proxima not only text, but graphical. text processing, graph editor.

An editor


\bl
\o what is Proxima~\cite{schrage04Proxima}.
\o Generic editor for variety of documents, but very suitable for editors programming language.
\o modeless combination of structure editing and free editing in the presentation
\o nothing is primitive, hence very customizable
\o example applications
\o Editor for Baysian networks
\o Generic editor as IDE
\o by giving type, pres, and parser, we get an environment almost for free
\o Helium editor
\o Implementation of Proxima
\el
\bl
\o contribution: algorithm for parsing mix of graphical and textual presentations.
\el

overview of paper 
\bc
\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{images/screenshots/BayesDocEditor}
\caption{The Bayesian network documentation editor.}
\label{fig:bayesEditor}
\end{figure}
\ec

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Proxima's layered architecture} \label{sect:tarchitecture}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The core architecture of Proxima consists of a number of layers, which only communicate with their direct neighbors. This layered structure is based on the staged nature of the presentation process. Instead of mapping a document directly onto its final rendering, it is first mapped onto an intermediate data structure. This intermediate data structure is mapped onto another intermediate data structure, until the last intermediate data structure is mapped onto the rendering.

The positions at which the document, the rendering, and the intermediate data structures reside are called {\em data levels}. Between each pair of levels is a {\em layer}, which is a component that maintains the mappings between the levels. Figure~\ref{fig:levelsAndLayers} schematically shows the levels and layers of Proxima. Only two data levels are visible to each layer: a higher and a lower level.\todo{name individual components and add sheets}

\begin{figure}[ht]
\centering
\includegraphics[width=4cm]{images/LevelLayerNames}
\caption{The levels and Layers of Proxima.}
\label{fig:levelsAndLayers}
\end{figure}

A data level in Proxima is not just an intermediate value in the presentation computation, but an entity in its own right. Together, the data levels constitute the state of the editor. The six data levels of Proxima are:


\begin{description}
\item[Document:] The edited document, the type of which is specified by a DTD or an EBNF grammar.

\item[Enriched Document:] The document enriched with computed information.

\item[Presentation:] A logical description of the presentation of the document, consisting of rows and columns of presentation elements with attributes. The presentation also supports formatting based on available space (e.g.\ line/page breaking).

\item[Layout:]  Presentation with explicit whitespace.\todo{and comments?}

\item[Arrangement:] Formatted presentation with absolute size and position information.

\item[Rendering:] A collection of user interface commands for drawing the absolutely positioned and sized arrangement.
\end{description}

Between each pair of adjacent levels is a layer that implements the mapping between the levels. We briefly discuss each of the five layers.

\head{\small Evaluation layer}
\noindent The evaluation layer takes care of computing derived structures and values over the document, and of mapping updates on these derived structures back to document updates. It is parameterized by an {\em evaluation sheet} and a {\em reduction sheet}, which specify the mappings. 

\head{\small Presentation layer}
\noindent The presentation layer consists of the presenter and the parser. The presenter takes an enriched document tree, and computes a presentation for it according to the {\em presentation sheet}. Its counterpart, the parser, maps a presentation tree on the enriched document and is parameterized by a {\em parsing sheet}.

\head{\small Layout layer}
\noindent The layout layer handles automatic whitespace. The layouter maps implicit whitespace, associated with tokens to actual linebreaks and spaces. The scanner recognizes tokens in the layout tree based on regular expressions specified in the {\em scanner sheet}. Since mapping tokens to strings is straightforward, the layouter does not need sheet parameter.

\head{\small Arrangement layer}
\noindent In the presentation direction, the arrangement layer computes the exacts sizes and positions for each element in the presentation. It also handles line breaking. In the interpretation direction, the only thing that needs to be done is to map absolute coordinates in edit commands to positions in the presentation tree. The arrangement level is not editables, so it need not be mapped back onto the layout level.

\head{\small Rendering layer}
\noindent The renderer creates a bitmap for the arrangement. Its counterpart maps edit gestures onto edit operations.

%\bl
%\o implementation: layer combinators.
%\o sometimes awkward, because we have to conform to the layers.
%\o but this has advantages: new GUI lib in a matter of days.
%\el

The two levels at which edit operations can take place are the document level and the layout level. After an edit operation on the document, all levels from document to rendering are updated to reflect the update. After an edit operation on the layout level, the modified layout is scanned, parsed and reduced, to obtain the corresponding document update, from which an updated rendering is computed. \todo{skipping layers}

In this paper, we focus mainly on the presentation layer and layout layer, and, more specifically, on the scanner and parser in these layers.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{The document structure}\label{sect:document}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The document type in Proxima is a monomorphic (i.e.\ parameter free) Haskell data type together with the list type. Below is the (partial) definition for a type \p{Exp} that has two constructors: one for fractions and one for if expressions. 


\begin{footnotesize}
\begin{verbatim}
data Exp = DivExp exp1:Exp exp2:Exp                      { idP0:IDP }
         | IfExp exp1:Exp exp2:Exp exp3:Exp              { idP0:IDP idP1:IDP idP2:IDP }
         | IntExp val:Int
\end{verbatim}
\end{footnotesize}

The named fields between braces, to the right of each constructor are used to keep track of the tokens used in the presentation. This information is more appropriate in the presentation sheet, but the current implementation does not yet analyse the presentation sheet in order to create the document type. A future version will remedy this situation.

Two special alternatives are added to each data type by Proxima: a {\em hole} and a {\em parse error} alternative. Hole alternatives are used during structural edits of the document tree. The parse error nodes make it possible to have a document tree even if its presentation contains a parse error.

Normally, the document is mapped onto an enriched document by the evaluator. However, since we leave the evaluator out of the discussion, the document and enriched document will be the same everywhere. Hence, we will sometimes speak of the document where in the actual architecture this will be the enriched document.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{The presentation process}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Before discussing the scanner and parser components, we briefly discuss their counterparts in the presentation direction: the presenter and layout components. The presenter component maps a document (or more precisely, an enriched document) onto the presentation level, according to rules in the presentation sheet. The presentation sheet is specified by means of an attribute grammar, and values of the presentation level are constructed with the presentation language \Xprez. Subsequently, the presentation is mapped onto the layout level by the layout component. In the next three sections, we introduce the language \Xprez, the attribute grammar formalism for the presentation sheet, and the layout component.

\subsection{The {\Xprez} presentation language} \label{sect:xprez}

\Xprez is a combinator library for specifying graphical presentations with support for stretching and alignment. For this paper, a short overview of the language suffices. A more complete description can be found in~\cite{schrage04Proxima}.

\begin{figure}
\begin{footnotesize}
\begin{center}
\begin{footnotesize}
\begin{verbatim}
empty             :: Xprez
text              :: String -> Xprez             
circle            :: Xprez                       
img               :: String -> Xprez             
poly              :: [(Float, Float)] -> Xprez 
row, col, overlay :: [Xprez]        -> Xprez          
rowR, colR        :: Int -> [Xprez] -> Xprez   
format            :: [Xprez]        -> Xprez
\end{verbatim}
\end{footnotesize}
\caption{The {\Xprez} primitives.} \label{fig:xprezPrim} 
\end{center}
\end{footnotesize}
\end{figure}

Figure~\ref{fig:xprezPrim} contains the \Xprez primitives. The basic building blocks of \Xprez are strings (\p{text}), tokens (\p{token}) and graphical elements such as polygons, circles, or images (\p{poly}, \p{circle}, \p{img}). With the combinators \p{row} and \p{col} presentations can be combined into rows and columns. The elements of a row or column are aligned according horizontal and vertical reference lines of their children, and do not overlap. If presentations need to overlap (for example in order to put a squiggly line under a string just below the baseline), the \p{overlay} combinator can be used. The \p{format} combinator produces a flow layout, creating rows for its children, based on available horizontal space.

Each presentation has a number of presentation attributes (e.g.\ color, font size, reference lines) that influence its appearance. Several functions are available for modifying presentation attributes. Examples are \p{withColor :: Color -> Xprez -> Xprez} and \p{withFontsize :: Int -> Xprez -> Xprez}. \todo{mention \p{with}?}


As an example, we show the \Xprez code that creates a graphical presentation of a fraction:

\begin{footnotesize}
\begin{verbatim}
pad xp = row [ hSpace 2, xp, hSpace 2 ]
shrink e = e `withFontSize_` (\fs -> (70 `percent` fs) `max` 10)
frac e1 e2 = let numerator   = hAlignCenter (pad (shrink e1) )
                 denominator = hAlignCenter (pad (shrink e2) )
             in  colR 2 [ numerator, vSpace 2, hLine
                        , vSpace 2, denominator ] `withHStretch` False
\end{verbatim}
\end{footnotesize}

The non-primitive library function \p{hAlignCenter} centers its argument horizontally. For shrinking presentations, we use the combinator \p{withFontSize\_ :: (Int -> Int) -> Xprez -> Xprez}, which takes a function argument that computes the new font size, given its previous value.

The result of \p{row [text "fraction = ", frac (text "1") (text "1+x")]}\\ 
is~~\includegraphics[width=3cm]{images/fracExample}

Besides the combinators that produce presentations, \Xprez also has a combinator for specifying edit operations in context menus, reactions to mouse clicks, and keeping track of document locations in the presentation. \todo{unclear}


\subsection{Document presentation}

For the presentation of the document, as well as for the computation of derived values and structures, Proxima uses the attribute grammar formalism (or AG). The presentation sheet is file with an AG definition, which is compiled to a Haskell program by the Utrecht University AG compiler~\cite{swierstra08ag}.

For each non-terminal, the AG defines a synthesized attribute \p{pres} of type \p{Presentation}.\todo{params} In the rule for \p{pres}, the presentations of child fields can be used. Besides the presentation, arbitrary synthesized and inherited attributes can be defined on the document tree. This way it is easy to specify static checks or for example the computation of all variables in scope at a certain document location. Moreover, external Haskell modules can be called, allowing for complex computations, such as type checking.

% also possible edit operations specific to the nonterminal.

A presentation may be either {\em structural} or {\em parsing}, with the difference that parsing presentations may be edited at the presentation level whereas structural presentation may not (although they may have parsing descendents that will be editable). 

A parsing presentation consists of a sequence of tokens, which may be strings or structural presentations. In the presentation sheet, the top-most element of the parsing presentation (which is an immediate child of a structural presentation) must specify a parser. This parser is applied to the sequence after it has been edited.

Since a structural presentation may not be edited at presentation level\todo{actually this is layout level}, it is straightforward to map a structural presentation back onto the document level. Hence, no parser needs to be specified in the presentation sheet.

Figure~\ref{fig:presentationSheet}\todo{add structural example without id (slide?)} shows two presentation rules for the type \p{Exp} from Section~\ref{sect:document}. Tokens are put in a list using the \p{row} combinator. The Haskell type system enforces that a parsing presentations consists only of rows and tokens. Two functions are available for creating tokens: \p{token} and \p{structuralToken}. The first parameter of both \p{token} and \p{structuralToken} is a presentation id, which is one of the p{IDP} fields that is declared in the data type. The function \p{frac} in the rule for \p{DivExp} is the function defined in Section~\ref{sect:xprez}.


\begin{figure}
\begin{center}
\begin{footnotesize}
\begin{verbatim}
SEM Exp
  | IfExp loc.pres = parsing $ row  $ [ key @idP0 "if",   @exp1.pres
                                      , key @idP1 "then", @exp2.pres
                                      , key @idP2 "else", @exp3.pres ]
  | DivExp
      loc.pres = structuralToken @idP0 $ frac @exp1.pres @exp2.pres
                  
key idp str = token idp str `withColor` blue 
\end{verbatim}%$
\end{footnotesize}
\caption{Presentation sheet fragment.} \label{fig:presentationSheet} 
\end{center}
\end{figure}

In each presentation rule there need to be a number of default function applications, for example to handle the display of focus, and to mark the document location in the presentation tree. Such functions may be applied by the writer of the presentation sheet, but this is awkward and error prone. Hence, rather than the definitions of synthesized attributes \p{pres} for each nonterminal, the presentation sheet contains definitions of a local attribute \p{pres}. An automatically generated rule for the synthesized \p{pres} then uses the local \p{pres} and adds the default functionality to it.

\subsection{Document layout}

% maybe get rid of this one
The main function of the scanner is to restore the implicit whitespace and presentation focus\todo{is this one introduced somewhere?} that has been recorded for each token in a parsing presentation. Whitespace is restored by looking up the token's whitespace in a white space map, which is kept at the presentation level, and inserting extra rows in the presentation for recorded linebreaks and strings of spaces for recorded spaces. 

Besides the whitespace, also the presentation focus is stored in the whitespace map. The scanner restores the presentation focus, so it will point to the tokens that had the focus during scanner. If automatic whitespace functionality is not used, the presentation focus is not recorded. In this case, the scanner will restore it by using its absolute coordinates in the presentation.

The layouter is not parameterized by a sheet parameter. The reason is that although we need a specification in order to create tokens from a string, the reverse process is quite easy since each token contains its string representation.  



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Scanner}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The basic function of the scanner is to map strings containing characters to tokens, which are specified by the user in the scanner sheet. But in Proxima, the scanner also performs several other functions. Any structural presentations that appear in the stream of tokens are put in special tokens. Such structural presentations may contain other structural presentations, or again parsing presentations, which are recursively scanned. Apart from this scanner also handles graph presentations. 


%\bl
%\o result is Structural [.. [PresentationTk]..]
%\el

\subsection{The \p{Token} type}

Figure~\ref{fig:tokenType} shows a simplified version of the \p{Token} data type. A number of type parameters that are not important for this discussion are hidden, as well as the constructors that have to do with Proxima's support for graph presentations. 

\begin{figure}
\begin{center}
\begin{tabbedCode}
data Token Location userToken\\ 
~~\= =  StructuralTk \= IDP Location Presentation \\
  \>                 \> [Token node userToken]\\
  \> | ParsingTk     \> IDP Location (Parser userToken)\\
  \>                 \> [Token node userToken]\\
  \> | UserTk        \> IDP Location userToken String \\
  \> | ErrorTk       \> IDP String \\
\end{tabbedCode}
\caption{The \p{Token} data type.} \label{fig:tokenType} 
\end{center}
\end{figure}

% Position is not shown ID has enough information
% Location

All constructors have an \p{IDP} field that is used to associate the token with whitespace and focus information, which is stored in a separate map. All tokens except \p{ErrorTk} have a \p{Location} field that refers to the node in the document tree from which the token originated. It is used when parsing structural presentations.\todo{ref to section?} 

\begin{description}
\item[\p{StructuralTk}:] represents a structural presentation and has a list of tokens for its child presentations. The \p{Presentation} field contains the structural presentation itself and is presented in case of a parse error \todo{maybe get rid of it} \todo{mention that hidden children are token from Location?} \\
\item[\p{ParsingTk}:] The field \p{Parsing userToken} is the associated parser that is used to parse the child tokens. It has no \p{Presentation} field, since in case of a parse error, the tokens are used to create the presentation. Note that a child presentation that is itself also parsing does not give rise to an extra \p{ParsingTk} token. Instead, tokens from all parsing descendents are collected and put in one list. This means that only \p{StructuralTk}, \p{UserTk}, and \p{ErrorTk} may appear in the child list. \\
\item[\p{UserTk}:] Represents a string token. \todo{Explain Location and reuse? Or just remove it?} \\
\item[\p{ErrorTk}:] This constructor is used to represent lexical errors. Section~\ref{sect:parseScanErrors} explains its use. \\
\end{description}



% Not shown: Presentation in StructuralTk

\subsection{The scanner sheet}

The lexical analysis of textual tokens is based on the Haskell lexical analyser generator Alex~\cite{marlow07alex}. Alex is a tool that generates an efficient lexical analyser based on a description of the tokens to be recognized in the form of regular expressions. It is comparable to the lex and flex tools for C and C++.

An editor designer has to define the data type \p{UserToken} and provide an Alex specification that defines the tokens. Figure~\ref{fig:scannerSheet} shows an example \p{UserToken} and scanner sheet. The Alex specification consists of a a number of macro definitions followed by a set of rules, each defining a token. A rule is a regular expression together with an action that constructs the token.

\begin{figure}
\begin{center}
\begin{footnotesize}
\begin{verbatim}
data UserToken = Ident String | Op String | Int Int

$lower = [a-z]
$upper = [A-Z]
$alpha = [$lower $upper]
$digit = 0-9		
$symChar = [\+ \- \= ]
tokens :-
 $digit+                       { mkToken $ \s -> Int (read s) }
 $symChar+                     { mkToken $ \s -> Sym s }
 $lower [$alpha $digit \_ \']* { mkToken $ \s -> Ident s }
\end{verbatim} %$
\end{footnotesize}
\caption{Example \p{UserToken} and scanner sheet.} \label{fig:scannerSheet} 
\end{center}
\end{figure}

The only difference between a normal Alex description and a Proxima scanner sheet is that each action needs to be preceded by a \p{mkToken} application. The \p{mkToken} application takes care of passing the internal scanner state, and constructs a \p{UserTk} alternative of type \p{Token}. \todo{mention it assigns IDP}



\subsection{Scanning the presentation}

The scanner traverses the layout tree and creates a tree of structural and parsing tokens that matches the structure of the presentation. The behavior of the scanner is determined by the kind of presentation on which it is called.


% How the tokenizer works:
\head{\small Structural presentation} 

\noindent A structural presentation of a document node is an Xprez tree that may contain presentations of child nodes. The scanner traverses the presentation tree and makes a recursive call on each child presentation that is encountered. Together with the entire presentation\p{recursively scanned?}, this list of child tokens is put in a \p{StructuralTk} and returned as the result of the scanner.

\head{\small Parsing presentation}

\noindent A parsing presentation consists of a column of rows, which contain either strings or structural presentations. Each structural presentation is mapped onto a structural token by recursively scanning it. The sequences of strings between the structural tokens are first extended with newline characters to mark the transitions between rows. The resulting lists of characters are mapped onto lists of \p{UserTk} tokens by applying the Alex scanner. The final list of child tokens is the result of merging the structural tokens with the user tokens.


\subsection{Handling whitespace}

% Whitespace
In order to use the automatic whitespace recognition, the following rule must be added to scanner sheet:

\begin{footnotesize}
\begin{verbatim}
  [\n \ ]+        { collectWhitespace }
\end{verbatim} %$
\end{footnotesize}

As a result, the scanner will emit special tokens for sequences of whitespace. A post processing phase removes these whitespace tokens, and creates an entry in the whitespace map for the whitespace and the presentation id of the preceding token in the list. \todo{focus}

% first token whitespace

\subsection{An example}

To further clarify the previous discussion, we give an example of a layout that is scanned with the scanner sheet in~\ref{fig:scannerSheet}.
% The presentation originates from a declaration of a value \p{x}:

\begin{center}
\includegraphics[width=1in]{images/scanFrac}\
\end{center}
\todo{rename f}

The presentation contains two structural presentations, one for the fraction, and one for the power. The scanner will return the following token structure: \todo{maybe add paths}
\begin{tabbedCode}
ParsingTk \= \\
~~ \= [ UserTk$_0$ (Ident "f") \\
   \> , UserTk$_1$ (Op "=") \\
   \> , StructuralTk$_2$ (DivExp (IntExp 1) (PlusExp ...))\\
   \> ~~~~ \= [ ParsingTk [ UserTk$_3$ (Int 1)] \\
   \>      \> , ParsingTk  \= [ StructParsingTk$_4$ (PowerExp (IntExp 3) (IntExp 2))\\
   \>      \>              \> ~~~~ \= [ ParsingTk [ UserTk$_5$ (Int 3) ] \\
   \>      \>              \>      \> , ParsingTk [ UserTk$_6$ (Int 2) ] \\
   \>      \>              \>      \> ] \\
   \>      \>              \> , UserTk$_7$ (Op "+") \\
   \>      \>              \> , UserTk$_8$ (Int 5) \\
   \>      \>              \> ] \\
   \>      \> ] \\
   \> , UserTk$_9$ (Op "+") \\
   \> , UserTk$_{10}$ (Int 1) \\
   \> ] \\
\end{tabbedCode}

\todo{explain that all tokens in a parsingTk contain refs to their originating nonterminal in the document?}
% In case of incomplete presentation, we reuse the fields from that node. Fragile. Copy/paste, retyping, it may get lost. So only for non-essential things. 

Together with the token structure, a whitespace map is returned. Each tuple encodes the number of trailing linebreaks and the number of trailing spaces. \todo{no good for spaces followed by linebreaks}

\noindent \begin{math}
\p{Whitespace}: =[ 0 \mapsto (0,1), 1 \mapsto (0,1), 2 \mapsto (0,1), 9 \mapsto (0,1), 10 \mapsto (1,0) ]
\end{math}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Parsing}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Unlike ordinary parsers, which take a list of tokens to produce a value, the Proxima parser is a function that takes only one token as input. This token can be either a structural token or a parsing token. In case of a structural token, the value is constructed automatically from the list of child tokens. If the token is a parsing token, its list of children is fed into the parser that was specified in the presentation sheet.

\subsection{Structural presentations}

A structural token corresponds to the presentation of a certain document node and contains a list of tokens that correspond to child-presentations that were part of the presentation of that document node. Each child may be presented multiple times, or even not at all. Furthermore, the order in which the child presentations appear may not correspond to the order of the children in their parent node.

Nevertheless, we can parse a structural token automatically, since all tokens contain a \p{Location} reference to the document node and path from which they were presented. Hence, we can deduce for each token the number of the child for which it is a presentation. Because structural presentations are not edited at the presentation level, this information will still be valid after presentation editing. 

For child$_i$ of the nonterminal, the scanner takes the list of tokens that contain presentations of that child. If this list is empty, the presentation does not contain the a presentation for the child, and we use its previous value, which is stored in the structural token. If the list is not empty, a presentation that has been edited is selected and it is recursively parsed to yield a value for child$_i$. In case no presentation has been edited, the child value is reused from the structural token.

There will not be multiple edited presentations, since Proxima does not allow editing another presentation until a successful parse cycle is achieved.

\todo{untyped, but safe}

\subsection{Parsing presentations}

A parsing not auto. instead it is spec'd in the presentation sheet. The parser simply applies the parser stored in the token to it's children.

Parsers are combinator parser with error recovery~\cite{swierstra03polishParsers, swierstra08parserCombinators}.
because of extra state (hidden presentations), and presentation ids, little bit extra info is kept
only when needed. Parser will be very similar to parser in a compiler.


In line with. we give the parser for expressions:\todo{mention that holes need to be explicitly parsed?}

Connection with parser is not fixed. in fact other module that parses tokens to document nodes can be used. Parsec~\cite{leijen08parsec}.



\section{Parse errors} \label{sect:parseScanErrors}

On a parse error, the parser does not return a document tree
we don't get a tree, so tricky to present. Parse and present should be identity (with squiggly for error). Won't appear in structural presentations, unless something is wrong in the presentation. In this case error is signaled. Problem for editor builder. In parsing presentations. Parse errors are normal, during programming most of the time not syntactically correct.

Approach: all nonterminals have a parseErr constructor. Insteafd of a value of type T, we get ParseErr\_T (is a value of type T). The parse error alternative has error loc + message and a list of tokens.

On presentation, the tokens are presented, and the location of the error gets a squiggly. Whitespace is added by the layouter as for any other token. Message is available as an attribute.

% lexical errors
Lexical errors pose a problem, since Alex stops at the character of the lexical error. Hence any following whitespace is not recorded. However, we do want the presentation of the lexical error to stay the same. Hence, an error token \todo{annoying that we haven't explained parse errors yet} is treated specially and expands its whitespace into spaces and line breaks.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Related work}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo{more?}

%\head{\small Eclipse}

%\noindent Eclipse~\cite{eclipse2001} is a Java-based platform for building integrated development environments. The platform has an open architecture, and can be easily extended through a plug-in mechanism. Eclipse includes a syntax-recognizing Java editor, which supports in-place type information, refactoring, as well as document-oriented edit operations. 

%Though it is not exactly a generic editor, Eclipse does have facilities for creating syntax-recognizing source editors. Unfortunately, building a code editor similar to the Java editor for a different language, requires a substantial amount of programming. Moreover, the presentation of the code is rather limited (lines of text), and there is no support for derived values appearing in the presentation.

\head{\small Barista, Citrus}

\noindent Barista~\cite{KoMyers06Barista} is a powerful framework for building code editors. It is built on top of Citrus~\cite{KoMyers05Citrus}, which is a UI toolkit together with an object-oriented language. Although Barista is targeted at code editors, the presentation of the code can be visual, for example allowing for images to appear in comments, or having graphical presentations of code. The editors created with Barista are syntax directed, but presentation-oriented editing is available. 

Because of the orientation towards code editing, word-processing editors will be harder to specify in Barista. The same holds for editors for which the structure of the presentation does not follow the structure of the document. Barista has no special support for derived values in the presentation or for editable derived structures.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Conclusion} 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bl
\o more static checks are possible
\o easy ways to increase speed after change management
\o dtd pres and parser give simple environment
\o use ag to add static/type checks
\el

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% References

\bibliographystyle{sbc}
\bibliography{../proxima}

\end{document}

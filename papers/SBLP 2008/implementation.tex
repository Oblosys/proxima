\documentclass[12pt]{article}

\usepackage{sbc-template}
\usepackage{graphicx,url}
\usepackage[latin1]{inputenc}  

\usepackage{../Utils}
\usepackage{implementation}     
\sloppy

\title{Beyond ASCII, parsing programs with graphical presentations \\{\small \version}}

\author{Martijn M. Schrage\inst{1}}


\address{Institute of Information and Computing Sciences\\ Utrecht University\\
    Utrecht, The Netherlands
  \email{martijn@cs.uu.nl}
}

\begin{document} 

\maketitle

\begin{abstract}
% 15 lines
Proxima is generic editor. although it has wp facilities, graphs, very suitable for programming languages. Structural and presentation-edit.

Pres may be graphical: fraction. When edited, need to parse this.

Solution that uses combinator parsers for simple stuff. Also automatic whitespace handling
\end{abstract}
     
\bc

Introduction (2)

Proxima's layered architecture (2)
- explanantion of presentation/interpretation processes
- overview of levels and layers
  (much can be taken from thesis chapter)
  
Presentation process
  
  Xprez (2)
  - short version of thesis chapter
  Presentation (2)
  - explanation of AG system
  - structural vs parsing
  - examples
   
Interpretation process 
  Scanner (2)
  - regular expression for specifying tokens
  - example
 
  Parser  (2)
   - structural vs parsing
   - uuag parser with only a few extra things
   - example
  Error handling in parser and scanner
 
Related work (1/2)
- synthesizer generator
- eclipse
- barista

Conclusions (1/2)

\ec

\section{Introduction}

\bl
\o what is Proxima~\cite{schrage04Proxima}.
\o Generic editor for variety of documents, but very suitable for editors programming language.
\o modeless combination of structure editing and free editing in the presentation
\o nothing is primitive, hence very customizable
\o example applications
\o Editor for Baysian networks
\o Generic editor as IDE
\o by giving type, pres, and parser, we get an environment almost for free
\o Helium editor
\o Implementation of Proxima
\el
\bl
\o contribution: algorithm for parsing mix of graphical and textual presentations.
\el

overview of paper 
\bc
\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{images/screenshots/BayesDocEditor}
\caption{The Bayesian network documentation editor}
\label{fig:bayesEditor}
\end{figure}
\ec

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Proxima's layered architecture} \label{sec:architecture}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The core architecture of Proxima consists of a number of layers, which only communicate with their direct neighbors. This layered structure is based on the staged nature of the presentation process. Instead of mapping a document directly onto its final rendering, it is first mapped onto an intermediate data structure. This intermediate data structure is mapped onto another intermediate data structure, until the last intermediate data structure is mapped onto the rendering.

The positions at which the document, the rendering, and the intermediate data structures reside are called {\em data levels}. Between each pair of levels is a {\em layer}, which is a component that maintains the mappings between the levels. Figure~\ref{fig:levelsAndLayers} schematically shows the levels and layers of Proxima. Only two data levels are visible to each layer: a higher and a lower level.\todo{name individual components and add sheets}

\begin{figure}[ht]
\centering
\includegraphics[width=4cm]{images/LevelLayerNames}
\caption{The levels and Layers of Proxima.}
\label{fig:levelsAndLayers}
\end{figure}

A data level in Proxima is not just an intermediate value in the presentation computation, but an entity in its own right. Together, the data levels constitute the state of the editor. The six data levels of Proxima are:


\begin{description}
\item[Document:] The edited document, the type of which is specified by a DTD or an EBNF grammar.

\item[Enriched Document:] The document enriched with computed information.

\item[Presentation:] A logical description of the presentation of the document, consisting of rows and columns of presentation elements with attributes. The presentation also supports formatting based on available space (e.g.\ line/page breaking).

\item[Layout:]  Presentation with explicit whitespace.\todo{and comments?}

\item[Arrangement:] Formatted presentation with absolute size and position information.

\item[Rendering:] A collection of user interface commands for drawing the absolutely positioned and sized arrangement.
\end{description}

Between each pair of adjacent levels is a layer that implements the mapping between the levels. We briefly discuss each of the five layers.

\head{\small Evaluation layer}
\noindent The evaluation layer takes care of computing derived structures and values over the document, and of mapping updates on these derived structures back to document updates. It is parameterized by an {\em evaluation sheet} and a {\em reduction sheet}, which specify the mappings. 

\head{\small Presentation layer}
\noindent The presentation layer consists of the presenter and the parser. The presenter takes an enriched document tree, and computes a presentation for it according to the {\em presentation sheet}. Its counterpart, the parser, maps a presentation tree on the enriched document and is parameterized by a {\em parsing sheet}.

\head{\small Layout layer}
\noindent The layout layer handles automatic whitespace. The layouter maps implicit whitespace, associated with tokens to actual linebreaks and spaces. The scanner recognizes tokens in the layout tree based on regular expressions specified in the {\em scanner sheet}. Since mapping tokens to strings is straightforward, the layouter does not need sheet parameter.

\head{\small Arrangement layer}
\noindent In the presentation direction, the arrangement layer computes the exacts sizes and positions for each element in the presentation. It also handles line breaking. In the interpretation direction, the only thing that needs to be done is to map absolute coordinates in edit commands to positions in the presentation tree. The arrangement level is not editables, so it need not be mapped back onto the layout level.

\head{\small Rendering layer}
\noindent The renderer creates a bitmap for the arrangement. Its counterpart maps edit gestures onto edit operations.

%\bl
%\o implementation: layer combinators.
%\o sometimes awkward, because we have to conform to the layers.
%\o but this has advantages: new GUI lib in a matter of days.
%\el

The two levels at which edit operations can take place are the document level and the layout level. After an edit operation on the document, all levels from document to rendering are updated to reflect the update. After an edit operation on the layout level, the modified layout is scanned, parsed and reduced, to obtain the corresponding document update, from which an updated rendering is computed. \todo{skipping layers}

In this paper, we focus mainly on the presentation layer and layout layer, and, more specifically, on the scanner and parser in these layers.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{The document structure}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bl
\o Document is main data type. Mapped to enriched, but left out of discussion, so equal.
\o Haskell types, no parameters
\el
\begin{footnotesize}
\begin{verbatim}
data Exp = DivExp exp1:Exp exp2:Exp                      { idP0:IDP }
         | IfExp exp1:Exp exp2:Exp exp3:Exp              { idP0:IDP idP1:IDP idP2:IDP }
\end{verbatim}
\end{footnotesize}

\bl
\o fields to store token id's for handling whitespace and focus
\o holes and parse errors added to each nonterminal
\o holes are for structure editing.
\el


\section{The presentation process}

Before discussing the scanner and parser components, we briefly discuss the presentation process. Presentation component, there is a specification (presentation rules) that map the document (more precisely the enriched document) to presentation target language, which is a Haskell combinator language Xprez. The rules are an attribute grammar.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\subsection{The {\Xprez} presentation language} \label{sect:xprez}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\Xprez is a combinator library for specifying graphical presentations with support for stretching and alignment. For this paper, a short overview of the language suffices. A more complete description can be found in~\cite{schrage04Proxima}.

\begin{figure}
\begin{footnotesize}
\begin{center}
\begin{footnotesize}
\begin{verbatim}
empty             :: Xprez
text              :: String -> Xprez             
circle            :: Xprez                       
img               :: String -> Xprez             
poly              :: [(Float, Float)] -> Xprez 
row, col, overlay :: [Xprez]        -> Xprez          
rowR, colR        :: Int -> [Xprez] -> Xprez   
format            :: [Xprez]        -> Xprez
\end{verbatim}
\end{footnotesize}
\caption{The {\Xprez} primitives} \label{fig:xprezPrim} 
\end{center}
\end{footnotesize}
\end{figure}

Figure~\ref{fig:xprezPrim} contains the \Xprez primitives. The basic building blocks of \Xprez are strings (\p{text}), tokens (\p{token}) and graphical elements such as polygons, circles, or images (\p{poly}, \p{circle}, \p{img}). With the combinators \p{row} and \p{col} presentations can be combined into rows and columns. The elements of a row or column are aligned according horizontal and vertical reference lines of their children, and do not overlap. If presentations need to overlap (for example in order to put a squiggly line under a string just below the baseline), the \p{overlay} combinator can be used. The \p{format} combinator produces a flow layout, creating rows for its children, based on available horizontal space.

Each presentation has a number of presentation attributes (e.g.\ color, font size, reference lines) that influence its appearance. Several functions are available for modifying presentation attributes. Examples are \p{withColor :: Color -> Xprez -> Xprez} and \p{withFontsize :: Int -> Xprez -> Xprez}. \todo{mention \p{with}?}


As an example, we show some \Xprez code that creates a graphical presentation of a fraction:

\begin{footnotesize}
\begin{verbatim}
pad xp = row [ hSpace 2, xp, hSpace 2 ]
shrink e = e `withFontSize_` (\fs -> (70 `percent` fs) `max` 10)
frac e1 e2 = let numerator   = hAlignCenter (pad (shrink e1) )
                 denominator = hAlignCenter (pad (shrink e2) )
             in  colR 2 [ numerator, vSpace 2, hLine
                        , vSpace 2, denominator ] `withHStretch` False
\end{verbatim}
\end{footnotesize}

The non-primitive library function \p{hAlignCenter} centers its argument horizontally. For shrinking presentations, we use the combinator \p{withFontSize\_ :: (Int -> Int) -> Xprez -> Xprez}, which takes a function argument that computes the new font size, given its previous value.

The result of \p{row [text "fraction = ", frac (text "1") (text "1+x")]}\\ 
is~~\includegraphics[width=3cm]{images/fracExample}

Besides the combinators that produce presentations, \Xprez also has a combinator for specifying edit operations in context menus, reactions to mouse clicks, and keeping track of document locations in the presentation. \todo{unclear}


\subsection{Document presentation}

For the presentation of the document, as well as for the computation of derived values and structures, Proxima uses the attribute grammar formalism (or AG). The presentation sheet is file with an AG definition, which is compiled to a Haskell program by the Utrecht University AG compiler~\cite{swierstra08ag}.

For each non-terminal, the AG defines a synthesized attribute \p{pres} of type \p{Presentation}.\todo{params} In the rule for \p{pres}, the presentations of child fields can be used. Besides the presentation, arbitrary synthesized and inherited attributes can be defined on the document tree. This way it is easy to specify static checks or for example the computation of all variables in scope at a certain document location. Moreover, external Haskell modules can be called, allowing for complex computations, such as type checking.

% also possible edit operations specific to the nonterminal.

A presentation may be either {\em structural} or {\em parsing}, with the difference that parsing presentations may be edited at the presentation level whereas structural presentation may not (although they may have parsing descendents that will be editable). 

A parsing presentation consists of a sequence of tokens, which may be strings or structural presentations. It is provided with a parser that is applied to the sequence of tokens when it has been edited. \todo{only top level if it is an immediate child of a structural}
\bl % or maybe near example
\o row is now used for making token sequence tokens.
\o we can enforce that only \p{token}s appear with a GADT!
\el


Since a structural presentation may not be edited at the pres,  be edited at the presentation level.
On the other hand, a parsing presentation consists of tokens (either strings or structural presentations) and is provided with a parser in the presentation sheet. Parsing presentations may be edited at the presentation level, after which the parser is applied to obtain the updated subtree.


\begin{footnotesize}
\begin{verbatim}
SEM Exp
  | IfExp loc.pres = parsing $ row  $ [ key @idP0 "if",   @exp1.pres
                                      , key @idP1 "then", @exp2.pres
                                      , key @idP2 "else", @exp3.pres ]
  | DivExp
      loc.pres = structuralID @idP0 $ frac @exp1.pres @exp2.pres
                  
key str = token str `withColor` blue 
\end{verbatim}%$
\end{footnotesize} % put this in a figure?

\bl
\o add structural example without id
\el

\p{frac} is the function defined in Section~\ref{sect:xprez}

In each presentation rule there need to be a number of default function applications, for example to handle the display of focus, and to mark the document location in the presentation tree. Such functions may be applied by the writer of the presentation sheet, but this is awkward and error prone. Hence, rather than the definitions of synthesized attributes \p{pres} for each nonterminal, the presentation sheet contains definitions of a local attribute \p{pres}. An automatically generated rule for the synthesized \p{pres} then uses the local \p{pres} and adds the default functionality to it.

\subsection{Document layout}

The layouter is currently not parameterized by any sheet
\bl
\o it adds layout explicitly, by looking it up in the map, and also restores the focus
\o if focus restore fails, focus is set on old coordinates (usually okay, explain when not)
\el


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Scanner}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The basic function of the scanner is to map strings containing characters to tokens, which are specified by the user in the scanner sheet. But in Proxima, the scanner also performs several other functions. Any structural presentations that appear in the stream of tokens are put in special tokens. Such structural presentations may contain other structural presentations, or again parsing presentations, which are recursively scanned. Apart from this scanner also handles graph presentations. 


\bl
\o result is Structural [.. [PresentationTk]..]
\el

\subsection{The \p{Token} type}

Figure~\ref{fig:tokenType} shows a simplified version of the \p{Token} data type. A number of type parameters that are not important for this discussion are hidden, as well as the constructors that have to do with Proxima's support for graph presentations. 
\begin{figure}
\begin{center}
\begin{tabbedCode}
data Token Location userToken\\ 
~~\= =  StructuralTk \= Position \= IDP Location Presentation \\
  \>                \> [Token node userToken]\\
  \> | ParsingTk    \>          \> IDP Location (Parser userToken)\\
  \>                \> [Token node userToken]\\
  \> | UserTk       \> Position IDP Location userToken String \\
  \> | ErrorTk      \> Position IDP String \\
\end{tabbedCode}
\caption{The \p{Token} data type} \label{xprezprim} 
\end{center}
\end{figure}

All constructors have an \p{IDP} field. used to associate the token with whitespace/focus. The \p{Position} only for elts that are actually parsed, not for \p{ParsingTk}.\todo{maybe idp also not necessary}.  \p{Maybe node} is document location
The \p{Location} field refers to the node in the document tree from which the token originated. It is used when parsing structural presentations.\todo{ref to section?}

The last constructor \p{ErrorTk}, is used to represent lexical errors. It's use is explained in Section~\ref{sect:parseScanErrors}

\bl
\o parsing has a parser associated
\o location in usertoken is for reuse (talk about this here?)
\o location in structural and parsing is for auto structurals
\o for structurals also for restoring fields that are note presented
\o lists of tokens are children.
\el

% Not shown: Presentation in StructuralTk

\subsection{The scanner sheet}

The lexical analysis of textual tokens is based on the Haskell lexical analyser generator Alex~\cite{marlow07alex}. Alex is a tool that generates an efficient lexical analyser based on a description of the tokens to be recognized in the form of regular expressions. It is comparable to the lex and flex tools for C and C++.

An editor designer has to define the data type \p{UserToken} and provide an Alex specification that defines the tokens. Figure~\ref{fig:scannerSheet} shows an example \p{UserToken} and scanner sheet. The Alex specification consists of a a number of macro definitions followed by a set of rules, each defining a token. A rule is a regular expression together with an action that constructs the token.

\begin{figure}
\begin{center}
\begin{footnotesize}
\begin{verbatim}
data UserToken = Ident String | Op String | Int Int

$lower = [a-z]
$upper = [A-Z]
$alpha = [$lower $upper]
$digit = 0-9		
$symChar = [\+ \- \= ]
tokens :-
 $digit+                       { mkToken $ \s -> Int (read s) }
 $symChar+                     { mkToken $ \s -> Sym s }
 $lower [$alpha $digit \_ \']* { mkToken $ \s -> Ident s }
\end{verbatim} %$
\end{footnotesize}
\caption{Example \p{UserToken} and scanner sheet} \label{fig:scannerSheet} 
\end{center}
\end{figure}

The only difference between a normal Alex description and a Proxima scanner sheet is that each action needs to be preceded by a \p{mkToken} application. The \p{mkToken} application takes care of passing the internal scanner state, and constructs a \p{UserTk} alternative of type \p{Token}. \todo{mention it assigns IDP}



\subsection{Scanning the presentation}

Scanner based on structural/parser


% How the tokenizer works:
\head{\small Structural presentation} 

\noindent A structural presentation of a document node is an Xprez tree that may contain presentations of child nodes. The scanner traverses the presentation tree and makes a recursive call on each child presentation that is encountered. It also stores the presentation in case of a parse error (recursively scanned). Yielding a StructuralTk.

\head{\small Parsing presentation}

\noindent A parsing presentation only consists of a column of rows, which contain either strings or structural presentations. scanner creates sequences of characters . Structurals are put in Structural tokens. the sequences of characters are converted to tokens by applying the Alex scanner.


\subsection{Handling whitespace}

% Whitespace
In order to use the automatic whitespace recognition, the following rule must be added to scanner sheet:

\begin{footnotesize}
\begin{verbatim}
  [\n \ ]+        { collectWhitespace }
\end{verbatim} %$
\end{footnotesize}

The result is that the scanner will also put whitespace tokens in the result of the If enabled, the final list of tokens will contain whitespace tokens. These are associated with the id of the preceding token's (may be structural).

% first token whitespace

\subsection{An example}

To clarify the previous discussion, we give an example of a scanned presentation. So this partially graphically presented function:
\begin{center}
\includegraphics[width=1in]{images/fraction}
\end{center}
\todo{add some whitespace}

leads to the following tokens:\todo{maybe add locators and paths}
\begin{tabbedCode}
ParsingTk \= \\
~~ \= [ UserTk$_0$ (Ident "f") \\
      \> , UserTk$_1$ (Op "=") \\
      \> , StructuralTk$_2$ (DivExp (IntExp 1) (PlusExp ...))\\
      \> ~~ ~~ \= [ ParsingTk [ UserTk$_3$ (Int 1)] \\
      \>            \>  , ParsingTk  \= [ StructParsingTk$_4$ (PowerExp (IntExp 3) (IntExp 2))\\
      \>            \>                 \> ~~~~ \= [ ParsingTk [ UserTk$_5$ (Int 3) ] \\
      \>            \>                 \>           \>  , ParsingTk [ UserTk$_6$ (Int 2) ] \\
      \>            \>                 \>           \> ] \\
      \>            \>                 \> , UserTk$_7$ (Op "+") \\
      \>            \>                 \> , UserTk$_8$ (Int 5) \\
      \>            \>                 \> ] \\
      \>            \> ] \\
      \> , UserTk$_9$ (Op "+") \\
      \> , UserTk$_{10}$ (Int 1) \\
      \> ] \\
\end{tabbedCode}

maybe: explain that all tokens in a parsingTk contain refs to their originating nonterminal in the document. In case of incomplete presentation, we reuse the fields from that node. Fragile. Copy/paste, retyping, it may get lost. So only for non-essential things. 

and a map containing the whitespace (and focus)

\begin{tabbedCode}
Whitespace = [ 0 -> (0,1), 1-> (0,1), 1 -> (1,0) ]
\end{tabbedCode}

Also put document node and path




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Parsing}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Unlike normal parsers, which take a list of tokens to produce a value, the Proxima parser is a function that takes only one token as input. This token can be either a structural token or a parsing token. In case of a structural token, the value is constructed automatically from the list of child tokens. If the token is a parsing token, its list of children is fed into the parser that was specified in the presentation sheet.

\subsection{Structural presentations}

A structural token corresponds to the presentation of a certain document node and contains a list of tokens that correspond to child-presentations that were part of the presentation of that document node. Each child may be presented multiple times, or even not at all. Furthermore, the order in which the child presentations appear may not correspond to the order of the children in their parent node.

Maybe an example? 
Nevertheless, we can parse a structural token automatically, since all tokens contain a \p{Locator} reference to the document node from which they were presented. \todo{Not destroyed because structurals not edited.}  By calling the parser recursively on the list of tokens, we obtain the document nodes for each child. .. The child tokens (either structural or parsing) contain document locators from which we can derive the child number.


Each token has ref to parent/path (cannot be broken in structural)

recognizeStructural
has a list of tokens, either structural or parsing. Each has information on origin as a path. so group them with their index in the parent.

Now recursively recognize each child. Either structural (this function), or Parsing (section ..). 

For any children that were not part of the presentation, we take the previous value from the locator of the StructuralTk that is currently parsed. And for doubles, at the moment, we take the first. But as soon as we keep track of dirty bits in the presentation, we take the edited child. If more edited either signal error, or take one. This can be prohibited by enforcing a parse cycle if we start editing another child.

\todo{untyped, but safe}

\subsection{Parsing presentations}

A \p{ParsingTk} token contains a parser that returns a value of .  a  we 
\bl
\o convert list of \p{Token} to document structure.
\o combinator parser with error recovery~\cite{swierstra03polishParsers, swierstra08parserCombinators}
\o because of extra state (hidden presentations), and presentation ids, little bit extra info is kept
\o only when needed
\o mention that holes need to be explicitly parsed?
\o in fact other module that parses tokens to document nodes can be used. Parsec~\cite{leijen08parsec}
\o Example
\el

\section{Parse errors} \label{sect:parseScanErrors}

On a parse error, we don't get a tree, so tricky to present. Parse and present should be identity (with squiggly for error). Won't appear in structural presentations, unless something is wrong in the presentation. In this case error is signaled. Problem for editor builder. In parsing presentations. Parse errors are normal, during programming most of the time not syntactically correct.

Approach: all nonterminals have a parseErr constructor. Insteafd of a value of type T, we get ParseErr\_T (is a value of type T). The parse error alternative has error loc + message and a list of tokens.

On presentation, the tokens are presented, and the location of the error gets a squiggly. Whitespace is added by the layouter as for any other token. Message is available as an attribute.

% lexical errors
Lexical errors pose a problem, since Alex stops at the character of the lexical error. Hence any following whitespace is not recorded. However, we do want the presentation of the lexical error to stay the same. Hence, an error token \todo{annoying that we haven't explained parse errors yet} is treated specially and expands its whitespace into spaces and line breaks.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Related work}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\todo{more?}

\head{\small Eclipse}

\noindent Eclipse~\cite{eclipse2001} is a Java-based platform for building integrated development environments. The platform has an open architecture, and can be easily extended through a plug-in mechanism. Eclipse includes a syntax-recognizing Java editor, which supports in-place type information, refactoring, as well as document-oriented edit operations. 

Though it is not exactly a generic editor, Eclipse does have facilities for creating syntax-recognizing source editors. Unfortunately, building a code editor similar to the Java editor for a different language, requires a substantial amount of programming. Moreover, the presentation of the code is rather limited (lines of text), and there is no support for derived values appearing in the presentation.

\head{\small Barista, Citrus}

\noindent Barista~\cite{KoMyers06Barista} is a powerful framework for building code editors. It is built on top of Citrus~\cite{KoMyers05Citrus}, which is a UI toolkit together with an object-oriented language. Although Barista is targeted at code editors, the presentation of the code can be visual, for example allowing for images to appear in comments, or having graphical presentations of code. The editors created with Barista are syntax directed, but presentation-oriented editing is available. 

Because of the orientation towards code editing, word-processing editors will be harder to specify in Barista. The same holds for editors for which the structure of the presentation does not follow the structure of the document. Barista has no special support for derived values in the presentation or for editable derived structures.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Conclusion} 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bl
\o more static checks are possible
\o easy ways to increase speed after change management
\o dtd pres and parser give simple environment
\o use ag to add static/type checks
\el

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% References

\bibliographystyle{sbc}
\bibliography{../proxima}

\end{document}
